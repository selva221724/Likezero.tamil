# Constants
FAKE_LABEL = 1  # Fake news label
TRUE_LABEL = 0  # True news label
LABEL_FIELD = 'label'   # Label field
TARGET_FIELD = 'text'   # Target field for the text to be trained
FAKE_DATA_PATH = 'data/Fake.csv'    # Fake news data path
TRUE_DATA_PATH = 'data/True.csv'    # True news data path
MODEL_NAME = 'distilbert-base-uncased' 
MAX_LENGTH = 512    # Maximum length of the input
BATCH_SIZE = 8 
EPOCHS = 3      # Number of epochs to train
LEARNING_RATE = 2e-5 
EPSILON = 1e-8      # Epsilon value for Adam optimizer
TRAIN_SIZE = 0.8    # Train size to split the data and rest will be test size
RANDOM_STATE = 42   # Random state for reproducibility
OUTPUT_DIR = './results'   # Output directory for the results
LOG_DIR = './logs'  # Log directory for the logs
EVALUATION_STRATEGY = 'epoch' 
SAVE_STRATEGY = 'epoch'     # Save strategy for the model
LOGGING_STEPS = 100     # Logging steps for the logs during training
SAVE_STEPS = 1000   # Save steps for the model
WEIGHT_DECAY = 0.01     # Weight decay for the optimizer
WARMUP_STEPS = 500  # Warmup steps for the optimizer
SAVE_MODEL = True   # if True, save the model
SAVE_MODEL_PATH = './model'     # Path to save the model